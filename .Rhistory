P = 4
K = 2
L_true = rnorm(K*P,mean = 0,sd = 1)
sigma2_true = 1
L_true = matrix(L_true,nrow = K,ncol = P)
F_true = matrix(0,nrow = K,ncol = P)
F_true[1,c(1,3)] = 1
F_true[2,c(2,4)] = 1
L_true = L_true * F_true
rho_true = rowSums(F_true)/P
View(F_true)
C = 3
mu_true = rbind(c(5,7),c(0,2),c(-5,-3))
Q_true = rbind(mvrnorm(50, c(rep(5,K/2),rep(7,K/2)), diag(K)/10),
mvrnorm(100, c(rep(0,K/2),rep(2,K/2)), diag(K)/10),
mvrnorm(50, c(rep(-5,K/2),rep(-3,K/2)), diag(K)/10) )
E_true = matrix(rnorm(N*P), nrow = N,ncol = P)/10
psi_true = rep(1,P)/10
Y = Q_true%*%L_true + E_true
prior_rho = list(s=200, r=0.1) ## rho_k ~ Beta(sr,s(1-r))
prior_muSig = list(mu0=rep(0,K), kappa0=1, Sigma0=diag(K), nu0=K+2)
## mu_l,Sigma_l ~ NIW(mu0,kappa0,Sigma0,nu0)
prior_psi = list(g2=1, h2=1) ## psi_j ~ IG(g2,h2)
prior_sigma2 = list(g=1, h=1) ## sigma2 ~ IG(g,h)
prior_alpha = list(s1=1, s2=1)
svd.Y = svd(Y)
ini.Q = svd.Y$u[, 1:K]%*%diag(svd.Y$d[1:K])
ini.Q = (ini.Q - mean(ini.Q))/sd(ini.Q) ## standardize
plot_ly(z = ini.Q%*%t(ini.Q), type = "heatmap")
ini.Lambda = solve(t(ini.Q)%*%ini.Q)%*%t(ini.Q)%*%Y
ini.Lambda1 = ini.Lambda
ini.Lambda[abs(ini.Lambda)<quantile(abs(ini.Lambda), 0.5)] = 0 ## sparse loading
ini.F = ini.Lambda
ini.F[ini.F != 0] = 1
ini.L = 3
total.L = 3
tmp = seq(0.01,1,0.01)
plot(tmp,tmp*log(tmp),type = 'l')
plot(tmp,tmp*log2(tmp),type = 'l')
plot(tmp,exp(-10*tmp),type = 'l')
plot(tmp,exp(-10*tmp^2),type = 'l')
p <- 5
q <- 100
sigma_y <- 1
sigma_x <- 1
n <- 200
k1 <- 3
k2 <- 8
h <- 1
d <- 1
alpha <- 10
set.seed(1)
lambda_y_true <- matrix(rnorm(p*k1), ncol = p, nrow = k1)
set.seed(2)
lambda_x_true <- matrix(rnorm(q*k1), ncol = q, nrow = k1)
lambda_u_true <- matrix(rnorm(q*k2)*sample(c(0, 1), q*k2, replace = T), ncol = q, nrow = k2)
Z_s <- matrix(rnorm(k1*n), ncol = k1, nrow = n)
require(MASS)
require(MCMCpack)
set.seed(2)
mus <- rbind(mvrnorm(1, rep(0, k2), 2*diag(k2)), mvrnorm(1, rep(1, k2), 2*diag(k2)),
mvrnorm(1, rep(-1, k2), 2*diag(k2)), mvrnorm(1, rep(2, k2), 2*diag(k2)),
mvrnorm(1, rep(-2, k2), 2*diag(k2)))
sigma.list <- list(NULL)
for(i in 1:5){
set.seed(i+1)
sigma.list[[i]] <- riwish(5+k2, diag(k2))
}
all.Q <- NULL
for(i in 1:5){
set.seed(i+1)
all.Q <- rbind(all.Q, mvrnorm(n/5, mus[i, ], sigma.list[[i]]))
}
X <- all.Q%*%lambda_u_true + matrix(rnorm(q*n), ncol = q, nrow = n)
K <- 5
ini.L <- 3
svd.X <- svd(X)
ini.Q <- svd.X$u[, 1:K]%*%diag(svd.X$d[1:K])
ini.Q <- (ini.Q - mean(ini.Q))/sd(c(ini.Q))
kmeans.cluster <- kmeans(ini.Q, ini.L)$cluster
ini.lambda.U <- solve(t(ini.Q)%*%ini.Q)%*%t(ini.Q)%*%X
ini.lambda.U[abs(ini.lambda.U) < quantile(abs(ini.lambda.U), 0.3)] <- 0
ini.F <- ini.lambda.U
ini.F[ini.F != 0] <- 1
ini.Mu <- NULL
ini.Sigma <- list(NULL)
for(i in 1:ini.L){
ini.Mu <- rbind(ini.Mu, apply(ini.Q[kmeans.cluster == i, ], 2, mean))
ini.Sigma[[i]] <- cov(ini.Q[kmeans.cluster == i, ])
}
totalL <- 20
ini.Mu <- rbind(ini.Mu, mvrnorm(totalL-ini.L+1, rep(0, K), 2*diag(K)))
for(i in (1 + ini.L):totalL){
ini.Sigma[[i]] <- riwish(8, diag(K))
}
Mu <- ini.Mu
Sigma <- ini.Sigma
Q <- ini.Q
F_current <- ini.F
C <- kmeans.cluster
lambda_u <- ini.lambda.U
psi_x <- diag(q)
sigma_v <- 1
sigma_v2_inv <- 1/sigma_v^2
alpha <- 1
v <- rep(0, totalL)
kappa_0 <- 1
nu_0 <- 10
r <- 0.1
s <- 200
m <- 0.75
mu_0 <- rep(0, K)
rho <- rbeta(K, r*s, s*(1-r))
Sigma_0 <- diag(K)
F_true = (lambda_u_true!=0)*1
View(F_true)
View(lambda_u)
View(lambda_u_true)
sum(F_true)
niter = 100
E2 = rep(NA,niter)
lambda_u.error= rep(NA,niter)
C.update = list()
for(iter in 1:niter){
####### Sample v_l ########
v_prod <- rep(1, length(v))
for(l in 1:totalL){
if(any(C == l)){
v[l] <- rbeta(1, 1 + length(C[C == l]), alpha + length(C[C > l]))
} else {
v[l] <- rbeta(1, 1, alpha)
}
if(l == 1){
v_prod[l] <- log(v[l])
} else {
v_prod[l] <- v_prod[l-1] + log(v[l])
}
}
####### Sample C_i ########
for(i in 1:n){
likelihood <- NULL
for(l in 1:totalL){
likelihood <- c(likelihood, v_prod[l] + dmvnorm(Q[i, ], Mu[l, ], Sigma[[l]], log = TRUE))
}
likelihood <- likelihood + abs(max(likelihood))
likelihood <- exp(likelihood)
prob <- likelihood/sum(likelihood)
C[i] <- sample(1:totalL, 1, prob = prob)
}
####### Sample Q_i ########
for(i in 1:n){
psi_x_inv <- diag(1/diag(psi_x))
D_inv <- solve(lambda_u%*%psi_x_inv%*%t(lambda_u) + solve(Sigma[[C[i]]]))
W_i <- (X[i, ]%*%psi_x_inv%*%t(lambda_u) + t(Mu[C[i], ])%*%solve(Sigma[[C[i]]]))%*%D_inv
Q[i, ] <- mvrnorm(1, W_i, D_inv)
}
####### Sample Mu_l, Sigma_l ########
for(l in 1:totalL){
if(any(C == l)){
n_l <- length(C[C == l])
sub.Q <- Q[C == l, ]
sum1 <- matrix(0, ncol = K, nrow = K)
if(n_l == 1){
sub.Q.mean <- sub.Q
} else {
sub.Q.mean <- apply(sub.Q, 2, mean)
for(kk in 1:n_l){
sum1 <- sum1 + (sub.Q[kk, ] - sub.Q.mean)%*%t(sub.Q[kk, ] - sub.Q.mean)
}
}
Sigma[[l]] <- riwish(nu_0 + n_l, Sigma_0 + sum1 + kappa_0*n_l*(sub.Q.mean - mu_0)%*%t(sub.Q.mean - mu_0)/(kappa_0 + n_l))
Mu[l, ] <- mvrnorm(1, (kappa_0*mu_0 + n_l*sub.Q.mean)/(kappa_0 + n_l), Sigma[[l]]/(kappa_0 + n_l))
}
}
for(j in 1:q){
B <- array(0, dim = c(n, K, q))
for(k in 1:K){
for(i in 1:n){
B[i, k, j] <- X[i, j] - sum(Q[i, -k]*lambda_u[-k, j])
}
sum_QB <- 0
for(i in 1:n){
sum_QB <- sum_QB + Q[i, k]*B[i, k, j]
}
sum_Q2 <- t(Q[, k])%*%Q[, k]
sigma_kj <- 1/(sum_Q2/diag(psi_x)[j] + sigma_v2_inv)
mu_kj <- sum_QB*sigma_kj/diag(psi_x)[j]
ratio.p <- log(m*rho[k]/(1 - m*rho[k]))
ratio <- 0.5*log(sigma_v2_inv*sigma_kj) + 0.5*sigma_kj^-1*mu_kj^2 + ratio.p
zero_prob <- 1/(exp(ratio)+1)
prob <- c(zero_prob, 1 - zero_prob)
aa <- sample(c(0, 1), 1, prob = prob)
F_current[k, j] <- aa
if(aa == 1){
lambda_u[k, j] <- rnorm(1, mu_kj, sqrt(sigma_kj))
} else {
lambda_u[k, j] <- 0
}
}
}
####### Sample rho_k ########
for(k in 1:K){
rho[k] <- rbeta(1, r*s + sum(F_current[k, ])/m, s*(1-r) + q - sum(F_current[k, ])/m)
}
##########
E_x <- X - Q%*%lambda_u
E2[iter] = sum((E_x)^2)
print(E2[iter])
psi_x_vector <- rep(0, q)
for(j in 1:q){
psi_x_vector[j] <- rigamma(1, 1 + n/2, h + sum((E_x[, j])^2)/2)
}
psi_x <- diag(psi_x_vector)
h <- rgamma(1, 1 + q, 1 + sum(psi_x_vector^-1))
######
sigma_v2 <- rigamma(1, 1 + sum(F_current)/2, d + sum(lambda_u[F_current==1]^2)/2)
sigma_v2_inv <- 1/sigma_v2
sigma_v <- sqrt(sigma_v2)
d <- rgamma(1, 1 + K, 1 + sigma_v2_inv*K)
###### alpha
#alpha <- rgamma(1, 1 + K, 1/(1 - sum(log(1-v))))
print(iter)
lambda_u.error[iter] = sum(abs(t(lambda_u)%*%lambda_u- t(lambda_u_true)%*%lambda_u_true)^2)
print(lambda_u.error[iter])
print(table(C))
C.update[[iter]] = C
}
plot(lambda_u.error,type = 'l')
lambda_u.error[100]
plot(E2,type = 'l')
print(sum(abs(t(lambda_u_support)%*%lambda_u_support- t(lambda_u_true_support)%*%lambda_u_true_support)^2))
lambda_u_support <- lambda_u
lambda_u_support[lambda_u_support != 0] <- 1
lambda_u_true_support <- lambda_u_true
lambda_u_true_support[lambda_u_true_support != 0] <- 1
print(sum(abs(t(lambda_u_support)%*%lambda_u_support- t(lambda_u_true_support)%*%lambda_u_true_support)^2))
niter = 300
lambda_u.error = rep(NA,niter)
F.error = rep(NA,niter)
C.update = list()
for(iter in 1:niter){
####### Sample v_l ########
v_prod <- rep(1, length(v))
for(l in 1:totalL){
if(any(C == l)){
v[l] <- rbeta(1, 1 + length(C[C == l]), alpha + length(C[C > l]))
} else {
v[l] <- rbeta(1, 1, alpha)
}
if(l == 1){
v_prod[l] <- log(v[l])
} else {
v_prod[l] <- v_prod[l-1] + log(v[l])
}
}
####### Sample C_i ########
for(i in 1:n){
likelihood <- NULL
for(l in 1:totalL){
likelihood <- c(likelihood, v_prod[l] + dmvnorm(Q[i, ], Mu[l, ], Sigma[[l]], log = TRUE))
}
likelihood <- likelihood + abs(max(likelihood))
likelihood <- exp(likelihood)
prob <- likelihood/sum(likelihood)
C[i] <- sample(1:totalL, 1, prob = prob)
}
####### Sample Q_i ########
for(i in 1:n){
psi_x_inv <- diag(1/diag(psi_x))
D_inv <- solve(lambda_u%*%psi_x_inv%*%t(lambda_u) + solve(Sigma[[C[i]]]))
W_i <- (X[i, ]%*%psi_x_inv%*%t(lambda_u) + t(Mu[C[i], ])%*%solve(Sigma[[C[i]]]))%*%D_inv
Q[i, ] <- mvrnorm(1, W_i, D_inv)
}
####### Sample Mu_l, Sigma_l ########
for(l in 1:totalL){
if(any(C == l)){
n_l <- length(C[C == l])
sub.Q <- Q[C == l, ]
sum1 <- matrix(0, ncol = K, nrow = K)
if(n_l == 1){
sub.Q.mean <- sub.Q
} else {
sub.Q.mean <- apply(sub.Q, 2, mean)
for(kk in 1:n_l){
sum1 <- sum1 + (sub.Q[kk, ] - sub.Q.mean)%*%t(sub.Q[kk, ] - sub.Q.mean)
}
}
Sigma[[l]] <- riwish(nu_0 + n_l, Sigma_0 + sum1 + kappa_0*n_l*(sub.Q.mean - mu_0)%*%t(sub.Q.mean - mu_0)/(kappa_0 + n_l))
Mu[l, ] <- mvrnorm(1, (kappa_0*mu_0 + n_l*sub.Q.mean)/(kappa_0 + n_l), Sigma[[l]]/(kappa_0 + n_l))
}
}
for(j in 1:q){
B <- array(0, dim = c(n, K, q))
for(k in 1:K){
for(i in 1:n){
B[i, k, j] <- X[i, j] - sum(Q[i, -k]*lambda_u[-k, j])
}
sum_QB <- 0
for(i in 1:n){
sum_QB <- sum_QB + Q[i, k]*B[i, k, j]
}
sum_Q2 <- t(Q[, k])%*%Q[, k]
sigma_kj <- 1/(sum_Q2/diag(psi_x)[j] + sigma_v2_inv)
mu_kj <- sum_QB*sigma_kj/diag(psi_x)[j]
ratio.p <- log(m*rho[k]/(1 - m*rho[k]))
ratio <- 0.5*log(sigma_v2_inv*sigma_kj) + 0.5*sigma_kj^-1*mu_kj^2 + ratio.p
zero_prob <- 1/(exp(ratio)+1)
prob <- c(zero_prob, 1 - zero_prob)
aa <- sample(c(0, 1), 1, prob = prob)
F_current[k, j] <- aa
if(aa == 1){
lambda_u[k, j] <- rnorm(1, mu_kj, sqrt(sigma_kj))
} else {
lambda_u[k, j] <- 0
}
}
}
####### Sample rho_k ########
for(k in 1:K){
rho[k] <- rbeta(1, r*s + sum(F_current[k, ])/m, s*(1-r) + q - sum(F_current[k, ])/m)
}
##########
E_x <- X - Q%*%lambda_u
# E2[iter] = sum((E_x)^2)
# print(E2[iter])
psi_x_vector <- rep(0, q)
for(j in 1:q){
psi_x_vector[j] <- rigamma(1, 1 + n/2, h + sum((E_x[, j])^2)/2)
}
psi_x <- diag(psi_x_vector)
h <- rgamma(1, 1 + q, 1 + sum(psi_x_vector^-1))
######
sigma_v2 <- rigamma(1, 1 + sum(F_current)/2, d + sum(lambda_u[F_current==1]^2)/2)
sigma_v2_inv <- 1/sigma_v2
sigma_v <- sqrt(sigma_v2)
d <- rgamma(1, 1 + K, 1 + sigma_v2_inv*K)
###### alpha
#alpha <- rgamma(1, 1 + K, 1/(1 - sum(log(1-v))))
print(iter)
lambda_u.error[iter] = sum(abs(t(lambda_u)%*%lambda_u- t(lambda_u_true)%*%lambda_u_true)^2)
print(lambda_u.error[iter])
F.error[iter] = sum(abs(t(F_current)%*%F_current- t(F_true)%*%F_true)^2)
print(F.error[iter])
print(table(C))
C.update[[iter]] = C
}
plot(F.error,type = 'l')
plot(lambda_u.error,type = 'l')
tmp = t(F_true)%*%F_true
View(tmp)
0.001/(0.001+0.0999)
set.seed(1)
niter= 100
coord = matrix(nrow = niter,ncol = 2)
i = 1
while (i <= niter){
u = runif(2)*2-1
if (u[1]^2+u[2]^2<=1){
coord[i,] = u
i = i+1
}
}
plot(coord[,1],coord[,2],pch=20)
library(pscl)
library(mvtnorm)
library(VennDiagram)
## Load BVS and Elastic net modeling functions:
source("BVS.R")
source("ElasticNet.R")
## Load the function that generates simulation data:
source("data_gen.R")
## Data Initialization
# load("ATAC-seq_PeakData/peak_counts.cqn.Rdata")
# peak.mean = colSums(peak_counts.cqn)/dim(peak_counts.cqn)[1]
# peak.cov = cov(as.matrix(peak_counts.cqn),method = 'pearson')
N = 50
P = 50
sparse = 0.2
niter = 1000
burn = 200
sigma2_e_true = 1
alpha_true = c(0.5,-2)
prior_sigma2e = list(g0=1,h0=1)
prior_sigma2b = list(g1=1,h1=1)
binary.A = F
X.sd = 1
Sigma2_b = c(0.2,seq(0.5,4,0.5))
stats.summary = data.frame(matrix(nrow = length(Sigma2_b), ncol = 9))
names(stats.summary) = c('sigma2_b','sparse','en.precision','en.recall','bvs.precision',
'bvs.recall','bvs.inv_spec','bvs.pp0','bvs.pp1')
rep = 30
seed0 = 12345
set.seed(seed0)
seeds = sample(100000,size=rep)
for (s in 1:length(Sigma2_b)){
sigma2_b_true = Sigma2_b[s]
print(paste("True sigma2_b:",sigma2_b_true))
stats.summary$sigma2_b[s] = sigma2_b_true
en = list(overlap = matrix(nrow = rep,ncol = 3))
bvs = list(overlap = matrix(nrow = rep,ncol = 3), means = matrix(nrow = rep,ncol = 4), pip = matrix(nrow = rep,ncol = 2))
for (i in 1:rep){
seed = seeds[i]
data = data.gen(N,P,peak.mean=NULL,peak.cov=NULL,X.sd,binary.A,sparse,alpha_true,sigma2_e_true,sigma2_b_true,seed)
X = data$X
y = data$y
A = data$A
beta_true = data$beta_true
en$overlap[i,] = EN.analysis(X,y,beta_true,seed)
stats = BVS(y,X,A,alpha_true,sigma2_e_true,sigma2_b_true,beta_true,prior_sigma2e,prior_sigma2b,niter,burn,seed)
bvs$overlap[i,] = stats$overlap
bvs$means[i,] = stats$means
bvs$pip[i,] = stats$pip
}
stats.summary$sparse[s] = mean(bvs$overlap[,1])/P
print(paste("Averaged sparsity:",mean(bvs$overlap[,1])/P))
stats.summary$en.precision[s] = mean(en$overlap[,3]/en$overlap[,2])
stats.summary$en.recall[s] = mean(en$overlap[,3]/en$overlap[,1])
stats.summary$bvs.precision[s] = mean(bvs$overlap[,3]/bvs$overlap[,2])
stats.summary$bvs.recall[s] = mean(bvs$overlap[,3]/bvs$overlap[,1])
stats.summary$bvs.inv_spec[s] = mean((bvs$overlap[,2]-bvs$overlap[,3])/(P-bvs$overlap[,1]))
stats.summary$bvs.pp0[s] = mean(bvs$pip[,1])
stats.summary$bvs.pp1[s] = mean(bvs$pip[,2])
}
plot(stats.summary$sigma2_b, stats.summary$bvs.precision, ylim = c(0,1), type = 'l',
xlab = 'sigma2_b', ylab = '', col = 'indianred1', main = paste('X.sd',X.sd),
cex.axis = 1.2)
points(stats.summary$sigma2_b, stats.summary$bvs.precision, pch=19, col = 'indianred1')
lines(stats.summary$sigma2_b, stats.summary$bvs.recall, type = 'l', col = 'indianred1')
points(stats.summary$sigma2_b, stats.summary$bvs.recall, pch = 17, col = 'indianred1')
lines(stats.summary$sigma2_b, stats.summary$en.precision, type = 'l',col='turquoise3')
points(stats.summary$sigma2_b, stats.summary$en.precision,pch=19, col = 'turquoise3')
lines(stats.summary$sigma2_b, stats.summary$en.recall, type = 'l',col='turquoise3')
points(stats.summary$sigma2_b, stats.summary$en.recall, pch = 17, col='turquoise3')
legend(x=2.5,y=0.3,legend = c('BVS precision','BVS recall','EN precision','EN recall'),
col = c('indianred1','indianred1','turquoise3','turquoise3'),
pch = c(19,17,19,17), bty = "n")
setwd("~/Google Drive/Research/DNA_footprint_and_ATAC-seq/Modeling/github")
library(pscl)
library(mvtnorm)
library(VennDiagram)
## Load BVS and Elastic net modeling functions:
source("BVS.R")
source("ElasticNet.R")
## Load the function that generates simulation data:
source("data_gen.R")
## Data Initialization
# load("ATAC-seq_PeakData/peak_counts.cqn.Rdata")
# peak.mean = colSums(peak_counts.cqn)/dim(peak_counts.cqn)[1]
# peak.cov = cov(as.matrix(peak_counts.cqn),method = 'pearson')
N = 50
P = 50
sparse = 0.2
niter = 1000
burn = 200
sigma2_e_true = 1
alpha_true = c(0.5,-2)
prior_sigma2e = list(g0=1,h0=1)
prior_sigma2b = list(g1=1,h1=1)
binary.A = F
X.sd = 1
Sigma2_b = c(0.2,seq(0.5,4,0.5))
stats.summary = data.frame(matrix(nrow = length(Sigma2_b), ncol = 9))
names(stats.summary) = c('sigma2_b','sparse','en.precision','en.recall','bvs.precision',
'bvs.recall','bvs.inv_spec','bvs.pp0','bvs.pp1')
rep = 30
seed0 = 12345
set.seed(seed0)
seeds = sample(100000,size=rep)
for (s in 1:length(Sigma2_b)){
sigma2_b_true = Sigma2_b[s]
print(paste("True sigma2_b:",sigma2_b_true))
stats.summary$sigma2_b[s] = sigma2_b_true
en = list(overlap = matrix(nrow = rep,ncol = 3))
bvs = list(overlap = matrix(nrow = rep,ncol = 3), means = matrix(nrow = rep,ncol = 4), pip = matrix(nrow = rep,ncol = 2))
for (i in 1:rep){
seed = seeds[i]
data = data.gen(N,P,peak.mean=NULL,peak.cov=NULL,X.sd,binary.A,sparse,alpha_true,sigma2_e_true,sigma2_b_true,seed)
X = data$X
y = data$y
A = data$A
beta_true = data$beta_true
en$overlap[i,] = EN.analysis(X,y,beta_true,seed)
stats = BVS(y,X,A,alpha_true,sigma2_e_true,sigma2_b_true,beta_true,prior_sigma2e,prior_sigma2b,niter,burn,seed)
bvs$overlap[i,] = stats$overlap
bvs$means[i,] = stats$means
bvs$pip[i,] = stats$pip
}
stats.summary$sparse[s] = mean(bvs$overlap[,1])/P
print(paste("Averaged sparsity:",mean(bvs$overlap[,1])/P))
stats.summary$en.precision[s] = mean(en$overlap[,3]/en$overlap[,2])
stats.summary$en.recall[s] = mean(en$overlap[,3]/en$overlap[,1])
stats.summary$bvs.precision[s] = mean(bvs$overlap[,3]/bvs$overlap[,2])
stats.summary$bvs.recall[s] = mean(bvs$overlap[,3]/bvs$overlap[,1])
stats.summary$bvs.inv_spec[s] = mean((bvs$overlap[,2]-bvs$overlap[,3])/(P-bvs$overlap[,1]))
stats.summary$bvs.pp0[s] = mean(bvs$pip[,1])
stats.summary$bvs.pp1[s] = mean(bvs$pip[,2])
}
plot(stats.summary$sigma2_b, stats.summary$bvs.precision, ylim = c(0,1), type = 'l',
xlab = 'sigma2_b', ylab = '', col = 'indianred1', main = paste('X.sd',X.sd),
cex.axis = 1.2)
points(stats.summary$sigma2_b, stats.summary$bvs.precision, pch=19, col = 'indianred1')
lines(stats.summary$sigma2_b, stats.summary$bvs.recall, type = 'l', col = 'indianred1')
points(stats.summary$sigma2_b, stats.summary$bvs.recall, pch = 17, col = 'indianred1')
lines(stats.summary$sigma2_b, stats.summary$en.precision, type = 'l',col='turquoise3')
points(stats.summary$sigma2_b, stats.summary$en.precision,pch=19, col = 'turquoise3')
lines(stats.summary$sigma2_b, stats.summary$en.recall, type = 'l',col='turquoise3')
points(stats.summary$sigma2_b, stats.summary$en.recall, pch = 17, col='turquoise3')
legend(x=2.5,y=0.3,legend = c('BVS precision','BVS recall','EN precision','EN recall'),
col = c('indianred1','indianred1','turquoise3','turquoise3'),
pch = c(19,17,19,17), bty = "n")
save(stats.summary,file = '../stats.summary.Rdata')
View(stats.summary)
